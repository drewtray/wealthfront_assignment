{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas_profiling import ProfileReport\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and display basic information\n",
    "loan_data = pd.read_csv('../data/loan_data.csv')\n",
    "loan_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze 'loan_status' (our target variable)\n",
    "\n",
    "loan_status_counts = loan_data['loan_status'].value_counts()\n",
    "loan_status_percentages = loan_data['loan_status'].value_counts(normalize=True)\n",
    "loan_status_df = pd.concat([loan_status_counts, loan_status_percentages], axis=1)\n",
    "loan_status_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the following columns are filled entirely with null values and should be dropped: wtd_loans, interest_rate, num_rate, numrate. There appear to be a large number of sparsely-populated records with 9524 non-nulls. These 476 records only contain loan_amnt, funded_amnt, and addr_state. These records do not appear to have a significantly different loan amount size or state distribution than the non-null data, so we are fine dropping them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = loan_data.loc[loan_data['total_pymnt'].isna(), ['loan_amnt', 'funded_amnt']].describe()\n",
    "df2 = loan_data.loc[~loan_data['total_pymnt'].isna(), ['loan_amnt', 'funded_amnt']].describe()\n",
    "\n",
    "combined_df = pd.concat([df1, df2], axis=1, keys=['total_pymnt is NaN', 'total_pymnt is not NaN'])\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = loan_data.loc[loan_data['total_pymnt'].isna(), 'addr_state'].value_counts(normalize=True)\n",
    "df2 = loan_data.loc[~loan_data['total_pymnt'].isna(), 'addr_state'].value_counts(normalize=True)\n",
    "\n",
    "combined_df = pd.concat([df1, df2], axis=1, keys=['total_pymnt is NaN', 'total_pymnt is not NaN'])\n",
    "combined_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate profiling report for additional analysis and alerts\n",
    "profile = ProfileReport(loan_data, title=\"Loan Data Report\")\n",
    "profile.to_file(\"../analysis_outputs/profile_report.html\")\n",
    "profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessary data pre-processing:\n",
    "\n",
    "    1. Drop unnecessary columns\n",
    "    2. Drop rows where only 'loan_amnt', 'funded_amnt', and 'addr_state' are non-null\n",
    "    3. Drop the 'In-Grace' period records\n",
    "    4. Combine loan statuses into \"good\" and \"bad\" categories\n",
    "    5. Convert the employment length to numeric values\n",
    "    6. Handle missing values (NaNs) for no employment history\n",
    "    7. Fill NaNs with zeroes in 'mths_since_last_delinq'\n",
    "    8. Replace '36 months' with 0 and '60 months' with numeric values\n",
    "    9. Group rare categories into 'OTHER'\n",
    "    10. Convert 'int_rate2' to float "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wealthfront",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
